{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting 48h weather forecast and past 7d weather from NWS via webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is intended to collect data from the National Weather Service (NWS) into a **_pandas_** dataframe and to create a simple overview figure using **_matplotlib_**. I am later planning to run this script periodically to create an updated figure. \n",
    "\n",
    "Data sources: \n",
    "1. [NWS Metar Reports](https://www.wrh.noaa.gov/zoa/getobext.php?sid=KCHO)\n",
    "2. [NWS Hourly Forecast](https://forecast.weather.gov/MapClick.php?lat=38.1386&lon=-78.4528&lg=english&&FcstType=digital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re \n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Station using NWS Site Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "SiteID = \"KCHO\"\n",
    "ReportSite = 'https://www.wrh.noaa.gov/zoa/getobext.php?sid=' + SiteID \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeNow = pd.to_datetime('today')\n",
    "YearNow = TimeNow.year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions to scape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to scrape met report \n",
    "def ScrapeMetReport(Page):\n",
    "    \"Scrape MetReport Data from NWS for Site with ID and return df(data), str(time of observation), and (coordinates)\"\n",
    "    soup = BeautifulSoup(Page.content, 'html.parser')\n",
    "    # Extract data from table body\n",
    "    table_body = soup.find('table',class_=\"inner-timeseries\")\n",
    "    rows = table_body.find_all('tr')\n",
    "    tabs=[]\n",
    "    HeaderLines = 3\n",
    "    ColumnNames1 = ['Time', 'Temperature', 'Dewpoint', 'Relative Humidity', 'Wind Dir', 'Surface Wind', 'Visibility', 'WX', 'Clouds', 'SLP', 'Altimeter',\n",
    "               'StationP', '6h TMAX', '6h TMIN', '24h TMAX', '24h TMIN','QC']\n",
    "    ColumnNames2 = ['Time', 'Temperature', 'Dewpoint', 'Relative Humidity', 'Wind Dir', 'Surface Wind', 'Visibility', 'WX', 'Clouds', 'SLP', 'Altimeter',\n",
    "               'StationP', 'Rain','P3h','P6h','P24h','6h TMAX', '6h TMIN', '24h TMAX', '24h TMIN','QC']\n",
    "\n",
    "    for row in rows[HeaderLines:]:\n",
    "        cols=row.find_all('td')\n",
    "        cols=[x.text.strip() for x in cols]\n",
    "        tabs.append(cols)\n",
    "    # and write data to dataframe\n",
    "    if (len(cols)==17):\n",
    "        df = pd.DataFrame(tabs, columns=ColumnNames1) \n",
    "    elif (len(cols) == 21):\n",
    "        df = pd.DataFrame(tabs, columns=ColumnNames2) \n",
    "    else:\n",
    "        raise Exception('Unexpected number of data columns MetReport')\n",
    "        \n",
    "    # Adjust to proper date\n",
    "    YDiff = YearNow-1900\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%d %b %H:%M %p')\n",
    "    df['Time'] = df['Time'].apply(lambda x: x + pd.DateOffset(years=YDiff))\n",
    "    \n",
    "    # Extract time of observations from website\n",
    "    table_body = soup.find_all('table')\n",
    "    rows = table_body[1].find_all('tr')\n",
    "    cols=rows[2].find_all('td')\n",
    "    cols=rows[3].find_all('td')\n",
    "    TimeObs = cols[1].get_text()\n",
    "    \n",
    "    # Extract Coordinates \n",
    "    LatLonStr = table_body[1].find_all(text=re.compile(\"Latitude\"))\n",
    "    LatLonStr = re.split(' |;',LatLonStr[0] )\n",
    "    Coord = tuple([w for w in LatLonStr if re.search('-?[0-9]{1,3}(?:\\.[0-9]{1,10})', w)])\n",
    "\n",
    "    return df, TimeObs, Coord \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to scrape met forecast\n",
    "def ScrapeForecast(Page):\n",
    "    \"Scrape 2-day forecast from NWS for Site and return df(data)\"\n",
    "    soup = BeautifulSoup(ForecastPage.content, 'html.parser')\n",
    "    # The site is a bit of a mess, structure wise. Simply get all table rows on site \n",
    "    rows = soup.find_all('tr')\n",
    "    tabs = []\n",
    "    for row in rows:\n",
    "        cols=row.find_all('td')\n",
    "        cols=[x.text.strip() for x in cols]\n",
    "        tabs.append(cols)\n",
    "    \n",
    "    # Select data by length of columns and get column names\n",
    "    ColNames = [item[0].split('(')[0].strip() for item in tabs if len(item)==25]\n",
    "    Data = [item[1:] for item in tabs if len(item)==25]\n",
    "\n",
    "    # Parse data into dataframe \n",
    "    df1 = pd.DataFrame(Data[:int(len(Data)/2)]).transpose()\n",
    "    df1.columns = ColNames[:int(len(Data)/2)]\n",
    "    df2 = pd.DataFrame(Data[int(len(Data)/2):]).transpose()\n",
    "    df2.columns = ColNames[int(len(Data)/2):]        \n",
    "    df = pd.concat([df1, df2])\n",
    "\n",
    "    # assemble date \n",
    "    df['Year']  = YearNow\n",
    "    df['Month'], df['Day'] = df['Date'].str.split('/', 1).str\n",
    "    df['Month']=pd.to_numeric(df['Month'])\n",
    "    df['Month']=df['Month'].fillna(method='ffill')\n",
    "    df['Day']=df['Day'].fillna(method='ffill')\n",
    "    df['Date'] = pd.to_datetime(dict(year=df['Year'], month=df['Month'], day=df['Day'], hour=df['Hour']))\n",
    "    df = df.rename(columns={'Date': 'Time'})\n",
    "    df.drop(['Year','Month','Day','Hour'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main body: Execute the code and return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Open page and parse to soup\n",
    "    ReportPage = requests.get(ReportSite)\n",
    "    RepDf, TimeObs, SiteCoord =ScrapeMetReport(ReportPage)\n",
    "except:\n",
    "    print('Failed to read MetReport - Something went wrong')\n",
    "    sys.exit()\n",
    "    \n",
    "#RepDf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://forecast.weather.gov/MapClick.php?lat=38.1374&lon=-78.4552&lg=english&&FcstType=digital'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assemble webpage of forcast for site location\n",
    "ForecastSite = 'https://forecast.weather.gov/MapClick.php?lat={:6.4f}&lon={:6.4f}&lg=english&&FcstType=digital'.format(float(SiteCoord[0]),float(SiteCoord[1]))\n",
    "#ForecastSite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Open page and parse to soup\n",
    "    ForecastPage = requests.get(ForecastSite)\n",
    "    ForecastDf =ScrapeForecast(ForecastPage)\n",
    "except:\n",
    "    print('Failed to read Forecast - Something went wrong')\n",
    "    sys.exit()\n",
    "    \n",
    "#ForecastDf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do ... Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work in progress "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
